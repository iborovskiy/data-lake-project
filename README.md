### Date created
2022-10-18


### Project Title
Udacity course project: Data Lake


### General Description
A startup called Sparkify wants to move their data warehouse to a Data Lake.

The goal of this project is to build an ETL pipeline that loads source data from S3 into a Spark cluster,
transforms original data into a set of fact and dimensional tables and loads that tables back into S3
for the analytics team to continue finding insights into what songs their users are listening to.

In this project, the following tasks were completed:
1. Establishing connection to pre-configured Redshift Cluster using IAM role that has read access to S3
2. Building ETL pipeline logic that loads data from S3 to into a Spark cluster
3. Building ETL pipeline logic that transforms original data to analytics tables
4. Building ETL pipeline logic that writes processed analytics tables into output S3 bucket


### Details of database schema design and ETL pipeline
For this project, we use a **star schema** optimized for queries on song play analysis.

Schema consists of the following tables:
- **songplays** - _fact table_: records in log data associated with song plays
- **users** - _dimension table_: users in the app
- **songs** - _dimension table_: songs in music database
- **artists** - _dimension table_: artists in music database
- **time** - _dimension table_: timestamps of records in **songplays** broken down into specific units (hour, day, week, month, year, etc.)


### Instructions for running the Python scripts
- You must load project directory to active EMR cluster in AWS
- File **etl.py** contains ETL pipeline to run as a Spark job


For ETL to work correctly, you must meet the following prerequisites:
- Launch a EMR Spark cluster and create an IAM role that has read access to S3
- Add **AWS_ACCESS_KEY_ID** and **AWS_SECRET_ACCESS_KEY** credentials for your account into **dl.cfg** file
- In main() function add S3 links to input (**input_data**) and output (**output_data**) s3 buckets


### Credits

**This entire project is based on learning materials from Udacity:**
https://learn.udacity.com/

The song dataset is a subset of real data from the Million Song Dataset:
http://millionsongdataset.com/

The log dataset consists of log files in JSON format generated by the following event simulator:
https://github.com/Interana/eventsim
